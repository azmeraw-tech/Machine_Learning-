**Modelâ€‘asâ€‘aâ€‘Service (MaaS) Seed Microâ€‘service**

`maasâ€‘seed` is a productionâ€‘ready template that turns any pickled scikitâ€‘learn model into a fully containerised prediction API. It:

* pulls the **latest model artefact from S3** at startup,
* caches it in **Redis** for hot-reload-free inference,
* exposes a **FastAPI** endpoint (`/Price_Estimation`) for real-time scoring, and
* (in dev) tunnels to a **remote Feast Python server** via `kubectl port-forward`, so you can pull online features without handâ€‘running `kubectl` every time.

---

## ğŸ—‚ï¸ Project Layout

```
maas-seed/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py            # FastAPI app + startup hook
â”‚   â”œâ”€â”€ api.py             # /Price_Estimation endpoint + validation
â”‚   â”œâ”€â”€ model_loader.py    # fetch newest model from S3
â”‚   â”œâ”€â”€ inference.py       # feature store call â†’ dataframe â†’ predict
â”‚   â””â”€â”€ redis_cache.py
â”‚
â”œâ”€â”€ Dockerfile             # FastAPI image (Python 3.10-slim)
â”œâ”€â”€ docker-compose.yml     # redis + fastapi + feast-tunnel
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ maas_txn.sh            # fetch creds, build & run services, clean up
â””â”€â”€ README.md              # you are here
```

---

## ğŸš€ Quickâ€‘start

Make the launcher script executable and run it:

```bash

chmod +x maas_run.sh

./maas_run.sh
```

This will:

1. Fetch AWS credentials from Secrets Manager.
2. Build and start all services via Docker Compose.

Then, access the interactive API documentation at [http://0.0.0.0:8036/docs#/](http://0.0.0.0:8000/docs#/) to explore the `/Price_Estimation` endpoint and other routes.

---

## ğŸ—‚ï¸ Environment Variables

All necessary AWS keys and other settings are handled by `maas_txn.sh`.

## ğŸ“„ License

MIT â€” free to use with attribution.

---

## ğŸ‘¥ Authors

Built by **Natnael** & the Data Science Team. Part of the scalable AI infrastructure at **KFT**.
